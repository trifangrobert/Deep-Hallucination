{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import torch \n","from torch import nn\n","from torch.optim import Adam\n","from torch.nn import CrossEntropyLoss, Linear, ReLU, Sequential\n","import cv2\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import numpy as np\n","import os\n","from torchvision import transforms"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T12:23:19.343859Z","iopub.status.busy":"2023-05-28T12:23:19.343163Z","iopub.status.idle":"2023-05-28T12:23:19.351616Z","shell.execute_reply":"2023-05-28T12:23:19.350409Z","shell.execute_reply.started":"2023-05-28T12:23:19.343824Z"},"trusted":true},"outputs":[],"source":["DATA_PATH = \"/kaggle/input/unibuc-ml-202325/\"\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","hyperparameters = {\n","    'batch_size': 64,\n","    'learning_rate': 0.001,\n","    'epochs': 15,\n","}"]},{"cell_type":"code","execution_count":101,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T12:23:19.353769Z","iopub.status.busy":"2023-05-28T12:23:19.353268Z","iopub.status.idle":"2023-05-28T12:23:19.362609Z","shell.execute_reply":"2023-05-28T12:23:19.361423Z","shell.execute_reply.started":"2023-05-28T12:23:19.353728Z"},"trusted":true},"outputs":[],"source":["class CustomImageDataset(Dataset):\n","    def __init__(self, img_dir, csv_file, transform=None):\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.img_labels = pd.read_csv(csv_file)\n","    def __len__(self):\n","        return len(self.img_labels)\n","    def __getitem__(self, index):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[index, 0])\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        label = self.img_labels.iloc[index, 1]\n","        if self.transform:\n","            image = self.transform(image)\n","        return (image, label)    "]},{"cell_type":"code","execution_count":102,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T12:23:19.365832Z","iopub.status.busy":"2023-05-28T12:23:19.365450Z","iopub.status.idle":"2023-05-28T12:23:19.377034Z","shell.execute_reply":"2023-05-28T12:23:19.376084Z","shell.execute_reply.started":"2023-05-28T12:23:19.365798Z"},"trusted":true},"outputs":[],"source":["class TestImageDataset(Dataset):\n","    def __init__(self, csv_file, img_dir, transform=None):\n","        self.df = pd.read_csv(csv_file)\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        img_id = self.df.iloc[index, 0]\n","        img_path = os.path.join(self.img_dir, img_id)\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        if self.transform:\n","            image = self.transform(image)\n","        return (image, img_id)\n"]},{"cell_type":"code","execution_count":103,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T12:23:19.379273Z","iopub.status.busy":"2023-05-28T12:23:19.378533Z","iopub.status.idle":"2023-05-28T12:23:19.406868Z","shell.execute_reply":"2023-05-28T12:23:19.406047Z","shell.execute_reply.started":"2023-05-28T12:23:19.379222Z"},"trusted":true},"outputs":[],"source":["transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((64, 64)), transforms.ToTensor()])\n","\n","train_dataset = CustomImageDataset(img_dir=DATA_PATH + \"train_images\", csv_file=DATA_PATH + \"train.csv\", transform=transform)\n","val_dataset = CustomImageDataset(img_dir=DATA_PATH + \"val_images\", csv_file=DATA_PATH + \"val.csv\", transform=transform)\n","test_dataset = TestImageDataset(img_dir=DATA_PATH + \"test_images\", csv_file=DATA_PATH + \"test.csv\", transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=hyperparameters['batch_size'], shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=hyperparameters['batch_size'], shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=hyperparameters['batch_size'], shuffle=False)"]},{"cell_type":"code","execution_count":104,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T12:23:19.408702Z","iopub.status.busy":"2023-05-28T12:23:19.408018Z","iopub.status.idle":"2023-05-28T12:23:19.412638Z","shell.execute_reply":"2023-05-28T12:23:19.411562Z","shell.execute_reply.started":"2023-05-28T12:23:19.408669Z"},"trusted":true},"outputs":[],"source":["# for i in test_loader:\n","#     print(i)\n","#     break"]},{"cell_type":"code","execution_count":105,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T12:23:19.414694Z","iopub.status.busy":"2023-05-28T12:23:19.413914Z","iopub.status.idle":"2023-05-28T12:23:19.428147Z","shell.execute_reply":"2023-05-28T12:23:19.427215Z","shell.execute_reply.started":"2023-05-28T12:23:19.414661Z"},"trusted":true},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self, num_classes=96):\n","        super(Net, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","\n","        self.classsifier = nn.Sequential(\n","            nn.Linear(512*2*2, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","\n","            nn.Linear(4096, num_classes)\n","        )\n","    \n","    def forward(self, x):\n","        x = self.features(x)\n","        x = torch.flatten(x, 1) # flatten all dimensions except batch, you can also use x.view(x.size(0), -1)\n","        x = self.classsifier(x)\n","        return x"]},{"cell_type":"code","execution_count":106,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T12:23:19.436560Z","iopub.status.busy":"2023-05-28T12:23:19.435928Z","iopub.status.idle":"2023-05-28T12:23:19.447932Z","shell.execute_reply":"2023-05-28T12:23:19.446924Z","shell.execute_reply.started":"2023-05-28T12:23:19.436521Z"},"trusted":true},"outputs":[],"source":["def train_model(train_loader, val_loader, hyperparameters):\n","    model = Net().to(device)\n","    criterion = CrossEntropyLoss()\n","    optimizer = Adam(model.parameters(), lr=hyperparameters['learning_rate'])\n","    num_epochs = hyperparameters['epochs']\n","\n","    for epoch in range(num_epochs):\n","        print(\"Starting epoch: \", epoch)\n","        # set the model to train mode\n","        # enable dropout, batch normalization etc.\n","        model.train()\n","#         print(len(train_loader))\n","#         step = 0\n","        for images, labels in train_loader:\n","#             step += 1\n","#             if (step % 50 == 0):\n","#                 print(\"Step: \", step)\n","            # loads the images to cuda if available\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images) # forward pass\n","            loss = criterion(outputs, labels) # compute the loss\n","\n","            optimizer.zero_grad() # reset the gradients because they accumulate by default\n","            loss.backward() # compute the gradients in the backward pass\n","            optimizer.step() # update the parameters based on the gradients computed in the backward pass\n","        print(\"Validating data...\")\n","        # set the model to evaluation mode\n","        # disable dropout, batch normalization etc.\n","        model.eval()\n","        with torch.no_grad(): # to disable gradient calculation and backpropagation\n","            correct = 0\n","            total = 0\n","            for images, labels in val_loader:\n","                # loads the images to cuda if availabl\n","                images = images.to(device)\n","                labels = labels.to(device)\n","\n","                outputs = model(images) # forward pass\n","                # torch.max returns a tuple (values, indices) where indices is the index of the maximum value of a tensor along a dimension\n","                _, predicted = torch.max(outputs.data, 1) # get the predicted class with highest probability\n","                total += labels.size(0) # total number of labels in a batch\n","                correct += (predicted == labels).sum().item() # total correct predictions\n","\n","            print('Epoch [{}/{}], Validation Accuracy: {:.2f}%'\n","                  .format(epoch+1, num_epochs, 100 * correct / total))\n","    \n","    return model, optimizer\n","\n","        "]},{"cell_type":"code","execution_count":107,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T12:23:19.452958Z","iopub.status.busy":"2023-05-28T12:23:19.452641Z","iopub.status.idle":"2023-05-28T12:23:19.461378Z","shell.execute_reply":"2023-05-28T12:23:19.460452Z","shell.execute_reply.started":"2023-05-28T12:23:19.452933Z"},"trusted":true},"outputs":[],"source":["def save_model(model, optimizer, path):\n","    state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict()}\n","    torch.save(state, path)\n","\n","def load_model(model, optimizer, path):\n","    state = torch.load(path)\n","    model.load_state_dict(state['model'])\n","    optimizer.load_state_dict(state['optimizer'])\n","    return model, optimizer"]},{"cell_type":"code","execution_count":108,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T12:23:19.463840Z","iopub.status.busy":"2023-05-28T12:23:19.463145Z","iopub.status.idle":"2023-05-28T12:23:19.473764Z","shell.execute_reply":"2023-05-28T12:23:19.472761Z","shell.execute_reply.started":"2023-05-28T12:23:19.463787Z"},"trusted":true},"outputs":[],"source":["def test_model(model, test_loader):\n","    model.eval()\n","    predicted_labels = []\n","    image_ids = []\n","    with torch.no_grad(): # to disable gradient calculation and backpropagation\n","        for images, ids in test_loader:\n","            images = images.to(device)\n","\n","            outputs = model(images) # forward pass\n","\n","            _, predicted = torch.max(outputs.data, 1) # get the predicted class with highest probability\n","\n","            predicted_labels.extend(predicted.tolist())\n","            image_ids.extend(ids)\n","    return predicted_labels, image_ids"]},{"cell_type":"code","execution_count":109,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T12:23:19.475813Z","iopub.status.busy":"2023-05-28T12:23:19.475359Z","iopub.status.idle":"2023-05-28T12:23:19.483791Z","shell.execute_reply":"2023-05-28T12:23:19.482832Z","shell.execute_reply.started":"2023-05-28T12:23:19.475780Z"},"trusted":true},"outputs":[],"source":["# print(torch.cuda.is_available())\n","# print(device)"]},{"cell_type":"code","execution_count":111,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T12:24:34.735771Z","iopub.status.busy":"2023-05-28T12:24:34.735067Z","iopub.status.idle":"2023-05-28T12:26:02.910735Z","shell.execute_reply":"2023-05-28T12:26:02.909133Z","shell.execute_reply.started":"2023-05-28T12:24:34.735736Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting epoch:  0\n","Validating data...\n","Epoch [1/15], Validation Accuracy: 3.60%\n","Starting epoch:  1\n","Validating data...\n","Epoch [2/15], Validation Accuracy: 3.60%\n","Starting epoch:  2\n","Validating data...\n","Epoch [3/15], Validation Accuracy: 3.60%\n","Starting epoch:  3\n","Validating data...\n","Epoch [4/15], Validation Accuracy: 3.60%\n","Starting epoch:  4\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[111], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# save_model(model, optimizer,  + \"models/model.pth\")\u001b[39;00m\n","Cell \u001b[0;32mIn[106], line 14\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, val_loader, hyperparameters)\u001b[0m\n\u001b[1;32m     11\u001b[0m         model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#         print(len(train_loader))\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#         step = 0\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#             step += 1\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#             if (step % 50 == 0):\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#                 print(\"Step: \", step)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;66;03m# loads the images to cuda if available\u001b[39;00m\n\u001b[1;32m     19\u001b[0m             images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m             labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[101], line 14\u001b[0m, in \u001b[0;36mCustomImageDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     12\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_labels\u001b[38;5;241m.\u001b[39miloc[index, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 14\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (image, label)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:166\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    165\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m--> 166\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    169\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:524\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyaccess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exif \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    526\u001b[0m         deprecate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_animated\u001b[39m\u001b[38;5;124m\"\u001b[39m, plural\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model, optimizer = train_model(train_loader, val_loader, hyperparameters)\n","# save_model(model, optimizer,  + \"models/model.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-28T12:24:32.650812Z","iopub.status.idle":"2023-05-28T12:24:32.651508Z","shell.execute_reply":"2023-05-28T12:24:32.651256Z","shell.execute_reply.started":"2023-05-28T12:24:32.651210Z"},"trusted":true},"outputs":[],"source":["predicted_labels, image_ids = test_model(model, test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-28T12:24:32.653575Z","iopub.status.idle":"2023-05-28T12:24:32.654042Z","shell.execute_reply":"2023-05-28T12:24:32.653825Z","shell.execute_reply.started":"2023-05-28T12:24:32.653802Z"},"trusted":true},"outputs":[],"source":["# print(predicted_labels[:10], image_ids[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-28T12:24:32.655730Z","iopub.status.idle":"2023-05-28T12:24:32.656189Z","shell.execute_reply":"2023-05-28T12:24:32.655975Z","shell.execute_reply.started":"2023-05-28T12:24:32.655953Z"},"trusted":true},"outputs":[],"source":["df_predictions = pd.DataFrame({\n","    'Image': image_ids,\n","    'Class': predicted_labels\n","})\n","\n","# Save the DataFrame to a CSV file\n","df_predictions.to_csv('submission.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
